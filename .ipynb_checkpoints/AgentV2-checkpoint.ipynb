{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "043ff3d7",
   "metadata": {},
   "source": [
    "# Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba9f5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import datetime\n",
    "from typing import List, Optional, Any, Dict\n",
    "from urllib.parse import urljoin\n",
    "import ollama\n",
    "\n",
    "import pandas as pd\n",
    "import magic\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import markdownify\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import (\n",
    "    PyMuPDFLoader, CSVLoader, JSONLoader, UnstructuredXMLLoader\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_qdrant import QdrantVectorStore, FastEmbedSparse, RetrievalMode\n",
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "\n",
    "from smolagents import (\n",
    "    CodeAgent, \n",
    "    LiteLLMModel, \n",
    "    DuckDuckGoSearchTool, \n",
    "    ToolCallingAgent, \n",
    "    tool, \n",
    "    VisitWebpageTool,\n",
    "    GoogleSearchTool\n",
    ")\n",
    "\n",
    "from abc import abstractmethod, ABC\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "#############################################################\n",
    "\n",
    "oc = ollama.Client(\"http://localhost:11434\")\n",
    "\n",
    "Data_dir = \"/users/formation/irtn7prtnc/LLM_Valdom/Dataset\"\n",
    "Cache_dir = \"/users/formation/irtn7prtnc/LLM_Valdom/Cache\"\n",
    "\n",
    "os.makedirs(Data_dir, exist_ok = True)\n",
    "os.makedirs(Cache_dir, exist_ok = True)\n",
    "\n",
    "model = LiteLLMModel(\n",
    "    model_id = \"ollama/qwen2.5-coder:32b\", #['deepseek-r1:32b', 'qwen2.5-coder:32b', 'llama3.1:8b', 'mistral-nemo:latest', 'mistral:latest']\n",
    "    api_base = \"http://localhost:11434/api/generate\",\n",
    "    num_ctx = 24000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b76fd",
   "metadata": {},
   "source": [
    "# Mise en place du RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bc72bd",
   "metadata": {},
   "source": [
    "### RAG definition (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47e2acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGInterface(ABC):\n",
    "    \"\"\"\n",
    "    Abstract class defining a generic RAG system. \n",
    "    \n",
    "    This class ensures that all RAG implementations follow a common structure.\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str, knowledge_db: Optional[Any] = None):\n",
    "        self.name = name  # Identifier for the RAG system\n",
    "        self.knowledge_db = knowledge_db  # Storage backend (e.g., a vector database)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def retrieve(self, query: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant contexts from the knowledge_db based on the query.\n",
    "        Args:\n",
    "            query (str): The user query.\n",
    "        Returns:\n",
    "            List[Document]: Retrieved document chunks.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate(self, query: str, retrieved_contexts: List[Document]) -> str:\n",
    "        \"\"\"\n",
    "        Generate a response based on the query and retrieved contexts.\n",
    "        Args:\n",
    "            query (str): The user query.\n",
    "            retrieved_contexts (List[Document]): Relevant document chunks.\n",
    "        Returns:\n",
    "            str: The generated response.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# Default prompt template for RAG\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use four sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {query}\n",
    "Context: {retrieved_contexts}\n",
    "Answer:\n",
    "\"\"\"\n",
    "######################## RAG BM25 ########################\n",
    "\n",
    "class BM25V0RAG(RAGInterface):\n",
    "    \"\"\"\n",
    "    Sparse Retrieval RAG using BM25 without embeddings for generation.\n",
    "    \n",
    "    - Stores text chunks in Qdrant using BM25 sparse retrieval.\n",
    "    - Retrieves the top-k relevant chunks based on keyword matching.\n",
    "    - Uses a language model to generate answers from retrieved contexts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, generation_model: OllamaLLM, docs_v0: List[Document]):\n",
    "        # Initialize BM25 sparse retrieval (no embeddings for generation)\n",
    "        sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "        # Store documents in Qdrant using sparse retrieval (BM25)\n",
    "        self.knowledge_db = QdrantVectorStore.from_documents(\n",
    "            docs_v0,  \n",
    "            embedding = OllamaEmbeddings(model=\"mistral\"),  # No embeddings used in this mode\n",
    "            sparse_embedding =s parse_embeddings,  # BM25 sparse embeddings\n",
    "            location = \":memory:\",  # Store in-memory (can be changed to persistent storage)\n",
    "            collection_name = \"rag_bm\",  # Collection name for BM25-based retrieval\n",
    "            retrieval_mode = RetrievalMode.SPARSE,  # Use only sparse retrieval (BM25)\n",
    "        )\n",
    "\n",
    "        # Define model name dynamically\n",
    "        name = f\"bm25_v0_{generation_model.model}\"\n",
    "        super().__init__(name = name, knowledge_db = self.knowledge_db)\n",
    "\n",
    "        # Initialize the LLM and retriever\n",
    "        self.llm = generation_model\n",
    "        self.retriever = self.knowledge_db.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": 5}  # Retrieve top 5 matches\n",
    "        )\n",
    "        self.gen_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)  # Use the structured prompt (no embeddings)\n",
    "\n",
    "    def add_documents(self, new_docs: List[Document]):\n",
    "        \"\"\"\n",
    "        Add new documents to Qdrant Cloud using BM25 sparse retrieval without embeddings.\n",
    "        This method adds documents directly using keyword matching (BM25).\n",
    "        \"\"\"\n",
    "\n",
    "        # Here we assume that new_docs are pre-processed and are in a list of Document objects\n",
    "        for doc in new_docs:\n",
    "            try:\n",
    "                # Adding document to Qdrant with BM25 indexing\n",
    "                # In this case, we don't use vector-based embeddings for the document\n",
    "                self.knowledge_db.add_documents([doc])  # Adding document to the database directly\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Erreur lors de l'ajout du document {doc.metadata.get('source', 'unknown')}: {e}\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Document]:\n",
    "        \"\"\"Retrieve relevant documents for a given query.\"\"\"\n",
    "        return self.retriever.invoke(query)\n",
    "\n",
    "    def find_relevant_documents(self, query: str) -> List[str]:\n",
    "        \"\"\"Find sources of relevant documents.\"\"\"\n",
    "        retrieved = self.retrieve(query)\n",
    "        return list(set(doc.metadata.get(\"source\", \"unknown\") for doc in retrieved))\n",
    "\n",
    "    def generate(self, query: str, retrieved_contexts: List[Document]) -> str:\n",
    "        \"\"\"\n",
    "        Generates a response using the retrieved contexts.\n",
    "\n",
    "        Args:\n",
    "            query (str): The user query.\n",
    "            retrieved_contexts (List[Document]): Retrieved document chunks based on BM25.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated answer from the language model.\n",
    "        \"\"\"\n",
    "        # Format retrieved contexts into a single string\n",
    "        format_retrieved_contexts = \"\\n\".join([rc.page_content for rc in retrieved_contexts])\n",
    "\n",
    "        # Format the query with the retrieved contexts for generation\n",
    "        augmented_query = self.gen_prompt.format(\n",
    "            query=query,\n",
    "            retrieved_contexts=format_retrieved_contexts\n",
    "        )\n",
    "\n",
    "        # Generate the final response\n",
    "        response = self.llm.invoke(augmented_query)\n",
    "        return response\n",
    "\n",
    "######################## RAG Hybride ########################\n",
    "\n",
    "class HybridRAG(RAGInterface):\n",
    "    \"\"\"\n",
    "    Retrieval-Augmented Generation with hybrid search (dense + sparse).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        generation_model: OllamaLLM, \n",
    "        docs: List[Document], \n",
    "        collection_name: str = \"rag_hybrid\", \n",
    "        alpha: float = 0.7,\n",
    "        embedding_model: str = \"mistral:latest\"):\n",
    "        \n",
    "        # Configurable sparse and dense embeddings\n",
    "        sparse_embeddings = FastEmbedSparse(model_name = \"Qdrant/bm25\", cache_dir=\".\")\n",
    "        dense_embeddings = OllamaEmbeddings(model = embedding_model)\n",
    "        \n",
    "        # Initialize vector store with hybrid search\n",
    "        self.vectorstore = QdrantVectorStore.from_documents(\n",
    "            docs,\n",
    "            embedding = dense_embeddings,\n",
    "            sparse_embedding = sparse_embeddings,\n",
    "            location = \":memory:\",\n",
    "            collection_name = collection_name,\n",
    "            retrieval_mode = RetrievalMode.HYBRID,\n",
    "            sparse_dense_ratio = alpha  # 0 = pure dense, 1 = pure sparse\n",
    "        )\n",
    "        \n",
    "        # Name with generation model\n",
    "        name = f\"hybrid_{generation_model.model}\"\n",
    "        super().__init__(name = name, knowledge_db = self.vectorstore)\n",
    "        \n",
    "        self.llm = generation_model\n",
    "        self.retriever = self.vectorstore.as_retriever(search_kwargs = {\"k\": 20})\n",
    "        self.gen_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    \n",
    "    def add_documents(self, new_docs: List[Document]):\n",
    "        \"\"\"Add new documents to the vector store.\"\"\"\n",
    "        self.vectorstore.add_documents(new_docs)\n",
    "    \n",
    "    def retrieve(self, query: str) -> List[Document]:\n",
    "        \"\"\"Retrieve relevant documents for a given query.\"\"\"\n",
    "        return self.retriever.invoke(query)\n",
    "    \n",
    "    def generate(self, query: str, retrieved_contexts: List[Document]) -> str:\n",
    "        \"\"\"Generate a response based on retrieved contexts.\"\"\"\n",
    "        context_str = \"\\n\".join([doc.page_content for doc in retrieved_contexts])\n",
    "        full_prompt = self.gen_prompt.format(query=query, retrieved_contexts=context_str)\n",
    "        return self.llm.invoke(full_prompt)\n",
    "    \n",
    "    def find_relevant_documents(self, query: str) -> List[str]:\n",
    "        \"\"\"Find sources of relevant documents.\"\"\"\n",
    "        retrieved = self.retrieve(query)\n",
    "        return list(set(doc.metadata.get(\"source\", \"unknown\") for doc in retrieved))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624aaea",
   "metadata": {},
   "source": [
    "### File pre-processing & RAG creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7301fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_chunk_file(file_path: str) -> List[Document]:\n",
    "    ext = file_path.split('.')[-1].lower()\n",
    "\n",
    "    if ext == \"pdf\":\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        for d in docs:\n",
    "            d.page_content = \" \".join(d.page_content.split())\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "        return splitter.split_documents(docs)\n",
    "\n",
    "    elif ext == \"csv\":\n",
    "        df = pd.read_csv(file_path)\n",
    "        if len(df) > 10000:\n",
    "            df = df.head(10000)\n",
    "        docs = [\n",
    "            Document(\n",
    "                page_content=\" \".join(str(value) for value in row if pd.notna(value)), \n",
    "                metadata={\"source\": file_path, \"row_index\": index}\n",
    "            )\n",
    "            for index, row in df.iterrows()\n",
    "        ]\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "        return splitter.split_documents(docs)\n",
    "\n",
    "    elif ext == \"json\":\n",
    "        try:\n",
    "            from langchain_community.document_loaders import JSONLoader\n",
    "            loader = JSONLoader(file_path, jq_schema=\".\", text_content=False)\n",
    "            docs = loader.load()\n",
    "        except ImportError:\n",
    "            print(f\"[Warning] jq non installé. Chargement brut de {file_path}\")\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw = f.read()\n",
    "            docs = [Document(page_content=raw, metadata={\"source\": file_path})]\n",
    "        \n",
    "        for d in docs:\n",
    "            try:\n",
    "                data = json.loads(d.page_content)\n",
    "                d.page_content = json.dumps(data, indent=2)\n",
    "            except:\n",
    "                pass\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "        return splitter.split_documents(docs)\n",
    "\n",
    "    elif ext == \"xml\":\n",
    "        loader = UnstructuredXMLLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        for d in docs:\n",
    "            d.page_content = \" \".join(d.page_content.split())\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        return splitter.split_documents(docs)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Extension non supportée : {ext}\")\n",
    "\n",
    "#############################################################\n",
    "\n",
    "def get_all_files_recursively(folder_path: str, valid_extensions: Optional[List[str]] = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parcourt récursivement un dossier et retourne tous les fichiers avec les extensions valides.\n",
    "    \"\"\"\n",
    "    all_files = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            ext = file.lower().split('.')[-1]\n",
    "            if valid_extensions is None or ext in valid_extensions:\n",
    "                full_path = os.path.join(root, file)\n",
    "    return all_files\n",
    "\n",
    "#############################################################\n",
    "\n",
    "def build_hybrid_rag_from_folder(folder_path: str, alpha: float = 0.7) -> HybridRAG:\n",
    "    \"\"\"\n",
    "    Construit un système HybridRAG à partir des fichiers dans un dossier (récursivement).\n",
    "    \"\"\"\n",
    "    valid_extensions = [\"pdf\", \"csv\", \"json\", \"xml\"]\n",
    "    file_paths = get_all_files_recursively(folder_path, valid_extensions)\n",
    "\n",
    "    all_docs = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            docs = load_and_chunk_file(path)\n",
    "            all_docs.extend(docs)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Erreur lors du traitement de {path} : {e}\")\n",
    "\n",
    "    llm = OllamaLLM(model=\"mistral:latest\")\n",
    "    rag = HybridRAG(generation_model=llm, docs=all_docs, alpha=alpha)\n",
    "    return rag\n",
    "\n",
    "#############################################################\n",
    "\n",
    "def build_rag_from_folder(folder_path: str) -> BM25V0RAG:\n",
    "    \"\"\"\n",
    "    Construit un système RAG à partir des fichiers dans un dossier (récursivement).\n",
    "    \"\"\"\n",
    "    valid_extensions = [\"pdf\", \"csv\", \"json\", \"xml\"]\n",
    "    file_paths = get_all_files_recursively(folder_path, valid_extensions)\n",
    "\n",
    "    all_docs = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            docs = load_and_chunk_file(path)\n",
    "            all_docs.extend(docs)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Erreur lors du traitement de {path} : {e}\")\n",
    "\n",
    "    llm = OllamaLLM(model=\"mistral:latest\")\n",
    "    # Remplacer \"docs\" par \"docs_v0\" pour correspondre au constructeur\n",
    "    rag = BM25V0RAG(generation_model=llm, docs_v0=all_docs)  \n",
    "    return rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c9854",
   "metadata": {},
   "source": [
    "### Création du RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b16d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = build_rag_from_folder(\"/users/formation/irtn7prtnc/llm_engineering/Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d4794",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Agent pourrait appeler ceci :\n",
    "query = \"Quelle est la région avec le plus de députés ?\"\n",
    "sources = rag.find_relevant_documents(query)\n",
    "print(\"🔍 Documents pertinents :\", sources)\n",
    "    \n",
    "answer = rag.generate(query, rag.retrieve(query))\n",
    "print(\"\\n🧠 Réponse :\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f700c8d",
   "metadata": {},
   "source": [
    "# Mise en place des Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5cb989",
   "metadata": {},
   "source": [
    "### RAG Agent tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d58419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def agent_add_file_to_rag(rag : str, path: str) -> str:\n",
    "    \"\"\"\n",
    "    Loads a supported file (PDF, CSV, JSON, XML), splits it into chunks, \n",
    "    and adds them to the RAG (Retrieval-Augmented Generation) system for future retrieval.\n",
    "    \n",
    "    This function is capable of handling both single files and entire directories. \n",
    "    If the path is a directory, all supported files within the directory (and its subdirectories) \n",
    "    will be processed.\n",
    "\n",
    "    Args:\n",
    "        rag: The RAG system or retriever to which the chunks will be added. This is the core component that stores and retrieves documents during question-answering tasks.\n",
    "        path: The path to the file or directory to be processed. Supported file formats include: pdf, csv, json & xml.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating the number of chunks added to the RAG, or an error message if the file format is unsupported or if an error occurs during processing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        docs = []\n",
    "        if os.path.isfile(path):\n",
    "            if path.endswith(('.pdf', '.csv', '.json', '.xml')):\n",
    "                docs = load_and_chunk_file(path)\n",
    "            else:\n",
    "                return f\"Format de fichier non supporté : {path}\"\n",
    "\n",
    "        elif os.path.isdir(path):\n",
    "            valid_exts = ('.pdf', '.csv', '.json', '.xml')\n",
    "            for root, _, files in os.walk(path):\n",
    "                for f in files:\n",
    "                    full_path = os.path.join(root, f)\n",
    "                    if full_path.endswith(valid_exts):\n",
    "                        try:\n",
    "                            docs.extend(load_and_chunk_file(full_path))\n",
    "                        except Exception as e:\n",
    "                            print(f\"[Erreur] Chargement échoué pour {full_path} : {e}\")\n",
    "        rag.add_documents(docs)\n",
    "        return f\"{len(docs)} chunks ajoutés depuis {path}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Le chemin donné n'est ni un fichier ni un dossier : {path}\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "@tool\n",
    "def detect_file_type(file_path: str) -> str:\n",
    "    \"\"\"Detects the MIME type of a file.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path of the file that we want the type.\n",
    "\n",
    "    Returns:\n",
    "        Tue file type of an error message if it's not possible to detecting the type.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mime = magic.Magic(mime=True)\n",
    "        return mime.from_file(file_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error detecting file type: {str(e)}\"\n",
    "    \n",
    "######\n",
    "\n",
    "@tool\n",
    "def extract_any_archive(file_path: str, destination: str = None) -> str:\n",
    "    \"\"\"Extracts a archive file to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path of the file to extract.\n",
    "        destination: The destination of the extracted file.\n",
    "    Returns:\n",
    "        The extracted file path, or an error message if file extraction failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if destination is None:\n",
    "            destination = os.path.splitext(file_path)[0]\n",
    "\n",
    "        patoolib.extract_archive(file_path, outdir=destination)\n",
    "\n",
    "        os.remove(zip_path)\n",
    "\n",
    "        return f\"Archive extracted successfully to: {destination}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting archive: {str(e)}\"\n",
    "    \n",
    "######\n",
    "\n",
    "@tool\n",
    "def move_file(source: str, destination: str) -> str:\n",
    "    \"\"\"Moves a file or directory to a new location.\n",
    "\n",
    "    Args:\n",
    "        source: The current path of the file to move.\n",
    "        destination: The new path of the file.\n",
    "\n",
    "    Returns:\n",
    "        The new file path, or an error message if file transfer failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(destination):\n",
    "            os.makedirs(destination)\n",
    "\n",
    "        shutil.move(source, destination)\n",
    "\n",
    "        return f\"File successfully move to : {destination}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Fail during file transfert : {str(e)}\"   \n",
    "\n",
    "######\n",
    "\n",
    "@tool\n",
    "def normalize_and_ensure_unique_filename(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes the name of a file or directory and ensures that it is unique \n",
    "    by appending a numerical suffix if a file with the same name already exists.\n",
    "\n",
    "    The function first replaces any non-alphanumeric characters (except for underscores, \n",
    "    hyphens, and periods) with underscores, and then checks if the normalized name \n",
    "    already exists. If it does, it appends a numerical suffix to the name.\n",
    "\n",
    "    Args:\n",
    "        path: The full path of the file or directory whose name is to be normalized and checked for uniqueness.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized and unique file or directory path.\n",
    "    \"\"\"\n",
    "    base = os.path.basename(path)\n",
    "    normalized_name = re.sub(r\"[^a-zA-Z0-9_\\-\\.]\", \"_\", base)\n",
    "\n",
    "    # Get the directory and ensure the file name is unique\n",
    "    directory = os.path.dirname(path)\n",
    "    unique_path = os.path.join(directory, normalized_name)\n",
    "\n",
    "    # Ensure uniqueness\n",
    "    if not os.path.exists(unique_path):\n",
    "        return unique_path\n",
    "\n",
    "    # If the file exists, append a numerical suffix\n",
    "    base, ext = os.path.splitext(normalized_name)\n",
    "    i = 1\n",
    "    while os.path.exists(os.path.join(directory, f\"{base}_{i}{ext}\")):\n",
    "        i += 1\n",
    "\n",
    "    return os.path.join(directory, f\"{base}_{i}{ext}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6db8f9",
   "metadata": {},
   "source": [
    "### Web Agent tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a53f4255",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def visit_webpage(url: str) -> str:\n",
    "    \"\"\"Fetches the content of a webpage and returns it in a clean Markdown format.\n",
    "\n",
    "    This tool sends an HTTP GET request to the provided URL, retrieves the HTML content,\n",
    "    converts it into Markdown to preserve readability while removing HTML-specific elements,\n",
    "    and returns the cleaned content. It automatically handles request errors and unexpected failures.\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the webpage to retrieve and convert.\n",
    "\n",
    "    Returns:\n",
    "        A string containing the converted Markdown content of the webpage,\n",
    "        or an error message if the request or conversion fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Convert the HTML content to Markdown\n",
    "        markdown_content = markdownify(response.text).strip()\n",
    "\n",
    "        # Remove multiple line breaks\n",
    "        markdown_content = re.sub(r\"\\n{3,}\", \"\\n\\n\", markdown_content)\n",
    "        return markdown_content\n",
    "\n",
    "    except RequestException as e:\n",
    "        return f\"Error fetching the webpage: {str(e)}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {str(e)}\"\n",
    "\n",
    "##########\n",
    "\n",
    "@tool\n",
    "def summarize_webpage(url: str) -> str:\n",
    "    \"\"\"Fetches the content of a webpage and summarizes it in a concise paragraph.\n",
    "\n",
    "    This tool first downloads the webpage, converts its HTML into Markdown, then\n",
    "    uses a language model to summarize the key points. Ideal for previewing large pages\n",
    "    or extracting meaningful information quickly.\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the webpage to summarize.\n",
    "\n",
    "    Returns:\n",
    "        A summary string of the page content, or an error message if the operation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from markdownify import markdownify\n",
    "        import re\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Convert HTML to Markdown\n",
    "        markdown_content = markdownify(response.text).strip()\n",
    "        markdown_content = re.sub(r\"\\n{3,}\", \"\\n\\n\", markdown_content)\n",
    "\n",
    "        # Trim if too long\n",
    "        if len(markdown_content) > 4000:\n",
    "            markdown_content = markdown_content[:4000] + \"...\"\n",
    "\n",
    "        # Call LLM (Qwen or another)\n",
    "        from langchain_core.runnables import Runnable\n",
    "        from langchain_core.prompts import PromptTemplate\n",
    "        from langchain_core.output_parsers import StrOutputParser\n",
    "        from langchain_community.llms import Ollama\n",
    "\n",
    "        llm = Ollama(model=\"mistral:latest\")\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"Summarize the following web content:\\n\\n{content}\\n\\nSummary:\"\n",
    "        )\n",
    "        chain: Runnable = prompt | llm | StrOutputParser()\n",
    "\n",
    "        return chain.invoke({\"content\": markdown_content})\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during summarization: {str(e)}\"  \n",
    "\n",
    "##########\n",
    "    \n",
    "@tool\n",
    "def check_url_validity(url: str) -> bool:\n",
    "    \"\"\"Downloads a file from a given URL to the local cache directory.\n",
    "\n",
    "    This tool initiates a streamed download of the file pointed to by the given URL,\n",
    "    saves it to a local cache folder, and returns the file path upon success.\n",
    "    It supports large files by downloading them in chunks.\n",
    "\n",
    "    Args:\n",
    "        url: The direct URL of the file to download.\n",
    "\n",
    "    Returns:\n",
    "        A confirmation message with the path to the downloaded file,\n",
    "        or an error message if the download fails.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.head(url, allow_redirects=True, timeout=5)\n",
    "        return response.status_code == 200\n",
    "\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "    \n",
    "##########\n",
    "\n",
    "@tool\n",
    "def download_file(url: str) -> str:\n",
    "    \"\"\"Checks if a URL is reachable and returns a boolean response.\n",
    "\n",
    "    This tool sends an HTTP HEAD request to the target URL to verify its availability,\n",
    "    following redirects if necessary. It's useful to ensure a link is valid before fetching or downloading.\n",
    "\n",
    "    Args:\n",
    "        url: The URL to verify for availability and accessibility.\n",
    "\n",
    "    Returns:\n",
    "        True if the URL is reachable (HTTP status 200), otherwise False.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        local_filename = os.path.join(Cache_dir, url.split('/')[-1])\n",
    "\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "\n",
    "            with open(local_filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        return f\"File downloaded with succes : {local_filename}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during file downloading: {str(e)}\"\n",
    "\n",
    "##########\n",
    "\n",
    "@tool\n",
    "def follow_links_recursive(url: str, depth: int = 4) -> List[str]:\n",
    "    \"\"\"Recursively explores hyperlinks on a webpage up to a given depth.\n",
    "\n",
    "    This tool fetches a webpage and extracts all links from it.\n",
    "    It then visits each discovered link (if it's a valid URL) and repeats\n",
    "    the process up to the specified recursion depth.\n",
    "\n",
    "    Args:\n",
    "        url: The starting URL to explore.\n",
    "        depth: The maximum depth of recursion. Depth 0 returns only the original URL.\n",
    "\n",
    "    Returns:\n",
    "        A list of all reachable URLs found during the recursive exploration.\n",
    "        May contain both relative and absolute URLs.\n",
    "    \"\"\"\n",
    "    from urllib.parse import urljoin, urlparse\n",
    "\n",
    "    visited = set()\n",
    "    result = set()\n",
    "\n",
    "    def crawl(current_url, current_depth):\n",
    "        if current_depth > depth or current_url in visited:\n",
    "            return\n",
    "        visited.add(current_url)\n",
    "\n",
    "        try:\n",
    "            response = requests.get(current_url, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            links = [urljoin(current_url, a[\"href\"]) for a in soup.find_all(\"a\", href=True)]\n",
    "            for link in links:\n",
    "                result.add(link)\n",
    "                crawl(link, current_depth + 1)\n",
    "        except Exception:\n",
    "            pass  # Skip errors silently\n",
    "\n",
    "    crawl(url, 0)\n",
    "    return list(result)\n",
    "\n",
    "##########\n",
    "\n",
    "@tool\n",
    "def extract_and_classify_links(url: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Extracts all hyperlinks from a webpage and classifies them into categories.\n",
    "\n",
    "    This tool visits the given URL, extracts all <a href> links, and organizes them into\n",
    "    the following categories:\n",
    "    - 'webpages': regular HTML pages or links without extensions\n",
    "    - 'files': downloadable documents (PDF, CSV, JSON, XML, ZIP, etc.)\n",
    "    - 'media': images, audio, video files (JPG, MP4, MP3, etc.)\n",
    "    - 'others': any remaining links\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the webpage to scan.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with link categories as keys and lists of corresponding URLs as values.\n",
    "    \"\"\"\n",
    "    file_exts = ('.pdf', '.csv', '.xlsx', '.xls', '.json', '.xml', '.zip')\n",
    "    media_exts = ('.png', '.jpg', '.jpeg', '.gif', '.mp4', '.mp3', '.wav', '.webm')\n",
    "\n",
    "    classified = {\n",
    "        \"webpages\": [],\n",
    "        \"files\": [],\n",
    "        \"media\": [],\n",
    "        \"others\": [],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"]\n",
    "            full_url = urljoin(url, href)\n",
    "            lower = full_url.lower()\n",
    "\n",
    "            if any(lower.endswith(ext) for ext in file_exts):\n",
    "                classified[\"files\"].append(full_url)\n",
    "            elif any(lower.endswith(ext) for ext in media_exts):\n",
    "                classified[\"media\"].append(full_url)\n",
    "            elif lower.startswith(\"http\") and (lower.endswith(\"/\") or \".\" not in lower.split(\"/\")[-1]):\n",
    "                classified[\"webpages\"].append(full_url)\n",
    "            else:\n",
    "                classified[\"others\"].append(full_url)\n",
    "\n",
    "        return classified\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": [f\"Error during extraction: {str(e)}\"]}\n",
    "\n",
    "##########\n",
    "\n",
    "@tool\n",
    "def get_keyword_context(url: str, keyword: str, window: int = 50) -> List[str]:\n",
    "    \"\"\"Extracts excerpts of text around a given keyword from a webpage.\n",
    "\n",
    "    This tool fetches the content of a webpage, converts it into plain text,\n",
    "    and searches for occurrences of the keyword. For each occurrence, it returns\n",
    "    a snippet that includes `window` words before and after the keyword.\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the webpage to analyze.\n",
    "        keyword: The keyword to search for in the text (case-insensitive).\n",
    "        window: The number of words to include before and after each match.\n",
    "\n",
    "    Returns:\n",
    "        A list of contextual excerpts where the keyword appears, or an error message if the request fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "        words = text.split()\n",
    "        keyword_lower = keyword.lower()\n",
    "        contexts = []\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            if keyword_lower in word.lower():\n",
    "                start = max(i - window, 0)\n",
    "                end = min(i + window + 1, len(words))\n",
    "                context = ' '.join(words[start:end])\n",
    "                contexts.append(context)\n",
    "\n",
    "        return contexts if contexts else [f\"No occurrences of '{keyword}' found.\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        return [f\"Error while extracting context: {str(e)}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ea86fa",
   "metadata": {},
   "source": [
    "### Data Agent tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d05f5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def find_relevant_documents(query: str) -> List[str]:\n",
    "    \"\"\"Finds the most relevant documents for a given user query using the local RAG system.\n",
    "\n",
    "    This tool queries the vector and sparse retrievers to find the most contextually relevant\n",
    "    documents or file paths related to the input query.\n",
    "\n",
    "    Args:\n",
    "        query: The user's question or search string.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings representing the most relevant documents or paths.\n",
    "    \"\"\"\n",
    "    sources = rag.find_relevant_documents(query)\n",
    "    return sources\n",
    "\n",
    "##########\n",
    "\n",
    "def parse_pdf(path: str) -> str:\n",
    "    import fitz  # PyMuPDF\n",
    "    try:\n",
    "        doc = fitz.open(path)\n",
    "        text = \"\\n\".join(page.get_text() for page in doc)\n",
    "        doc.close()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error parsing PDF: {str(e)}\"\n",
    "\n",
    "def parse_csv(path: str) -> str:\n",
    "    import pandas as pd\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        return df.head(10).to_markdown()\n",
    "    except Exception as e:\n",
    "        return f\"Error parsing CSV: {str(e)}\"\n",
    "    \n",
    "def parse_json(path: str) -> str:\n",
    "    import json\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return json.dumps(data, indent=2)[:3000]  # Trimmed for safety\n",
    "    except Exception as e:\n",
    "        return f\"Error parsing JSON: {str(e)}\"\n",
    "\n",
    "def parse_xml(path: str) -> str:\n",
    "    import xml.etree.ElementTree as ET\n",
    "    try:\n",
    "        tree = ET.parse(path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        def parse_element(elem, level=0):\n",
    "            text = f\"{'  ' * level}<{elem.tag}>: {elem.text.strip() if elem.text else ''}\\n\"\n",
    "            for child in elem:\n",
    "                text += parse_element(child, level + 1)\n",
    "            return text\n",
    "\n",
    "        return parse_element(root)\n",
    "    except Exception as e:\n",
    "        return f\"Error parsing XML: {str(e)}\"\n",
    "     \n",
    "###########\n",
    "\n",
    "@tool\n",
    "def detect_and_parse(path: str) -> str:\n",
    "    \"\"\"Automatically detects the type of a local file and parses its content accordingly.\n",
    "\n",
    "    This tool acts as a smart wrapper that routes the file to the appropriate parser based\n",
    "    on its extension (PDF, CSV, JSON, XML). It is ideal for agents that don't know in advance\n",
    "    what type of file they are dealing with.\n",
    "\n",
    "    Use this tool when the user provides a file path and wants to:\n",
    "    - View or analyze the content, regardless of the file type.\n",
    "    - Extract text or structure without needing to specify the format.\n",
    "\n",
    "    Args:\n",
    "        path: Path to the file.\n",
    "\n",
    "    Returns:\n",
    "        The parsed content or structure of the file, or an error message.\n",
    "    \"\"\"\n",
    "    ext = path.lower().split(\".\")[-1]\n",
    "    if ext == \"pdf\":\n",
    "        return parse_pdf(path)\n",
    "    elif ext == \"csv\":\n",
    "        return parse_csv(path)\n",
    "    elif ext == \"json\":\n",
    "        return parse_json(path)\n",
    "    elif ext == \"xml\":\n",
    "        return parse_xml(path)\n",
    "    else:\n",
    "        return \"Unsupported file type\"\n",
    "\n",
    "###########\n",
    "\n",
    "@tool\n",
    "def get_document_metadata(path: str) -> Dict[str, str]:\n",
    "    \"\"\"Returns metadata information about a local document file.\n",
    "\n",
    "    Use this tool when the user wants to inspect technical information about a file such as\n",
    "    size, type, name, and last modification date.\n",
    "\n",
    "    Args:\n",
    "        path: The local path to the document file.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing metadata about the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stat = os.stat(path)\n",
    "        metadata = {\n",
    "            \"name\": os.path.basename(path),\n",
    "            \"size (KB)\": f\"{stat.st_size // 1024}\",\n",
    "            \"last_modified\": datetime.fromtimestamp(stat.st_mtime).isoformat(),\n",
    "            \"type\": os.path.splitext(path)[1].lower()\n",
    "        }\n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "###########    \n",
    "    \n",
    "@tool\n",
    "def get_keyword_context(path: str, keyword: str, window: int = 50) -> List[str]:\n",
    "    \"\"\"Extracts short text segments around a keyword from a local document.\n",
    "\n",
    "    Use this tool when the user is searching for how a specific term is used inside a\n",
    "    document. It returns snippets that include the keyword and surrounding words.\n",
    "\n",
    "    Args:\n",
    "        path: Path to the local file.\n",
    "        keyword: The target word or phrase to search.\n",
    "        window: Number of words before and after the keyword to include.\n",
    "\n",
    "    Returns:\n",
    "        A list of text excerpts, or a message if no match is found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = detect_and_parse(path)\n",
    "        words = content.split()\n",
    "        keyword_lower = keyword.lower()\n",
    "        contexts = []\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            if keyword_lower in word.lower():\n",
    "                start = max(i - window, 0)\n",
    "                end = min(i + window + 1, len(words))\n",
    "                context = ' '.join(words[start:end])\n",
    "                contexts.append(context)\n",
    "\n",
    "        return contexts if contexts else [f\"No occurrences of '{keyword}' found.\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        return [f\"Error while extracting context: {str(e)}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0890ce7",
   "metadata": {},
   "source": [
    "### Définition des Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f3c5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_agent = ToolCallingAgent(\n",
    "    tools = [agent_add_file_to_rag, extract_any_archive, move_file, normalize_and_ensure_unique_filename],\n",
    "    model = model,\n",
    "    add_base_tools = True,\n",
    "    max_steps = 10,\n",
    "    name = \"RAG_Agent\",\n",
    "    description = \"\"\"RAG_Agent is a local retrieval-augmented generation (RAG) agent designed to manage, process, and store documents within a retrieval system.\n",
    "    It supports various file types such as PDF, CSV, JSON, and XML. The agent can download, extract, normalize, and ensure uniqueness of document paths. \n",
    "    It integrates file handling capabilities like moving files to specific locations and adding them to a retrieval-augmented system for future queries. \n",
    "    RAG_Agent is ideal for organizing data, handling large document collections, and enhancing knowledge retrieval capabilities.\n",
    "    This agent works with a local RAG system to optimize document storage and querying, ensuring seamless integration of newly added files or directories.\"\"\"\n",
    "    )\n",
    "\n",
    "#############################################################\n",
    "\n",
    "data_agent = ToolCallingAgent(\n",
    "    tools = [find_relevant_documents, detect_and_parse, get_document_metadata, get_keyword_context],\n",
    "    model = model,\n",
    "    add_base_tools = True,\n",
    "    max_steps = 10,\n",
    "    name = \"Data_agent\",\n",
    "    description =\"\"\"DataAgent is a local data analysis agent designed to understand and extract insights from documents stored on the local file system.\n",
    "    It supports multiple file types — PDF, CSV, JSON, and XML — and can intelligently detect and parse files, find relevant documents using a local RAG \n",
    "    system, summarize content, answer questions, and locate context around keywords.\n",
    "    With access to powerful file-specific tools, DataAgent provides a flexible and intelligent interface for navigating structured and unstructured data, \n",
    "    especially in research, compliance, business reporting, and document management use cases.\"\"\"\n",
    "    )\n",
    "\n",
    "#############################################################\n",
    "\n",
    "web_agent = ToolCallingAgent(\n",
    "    tools = [visit_webpage, summarize_webpage, check_url_validity, download_file, follow_links_recursive, extract_and_classify_links, GoogleSearchTool()],\n",
    "    model = model,\n",
    "    add_base_tools = True,\n",
    "    max_steps = 20,\n",
    "    name=\"Web_agent\",\n",
    "    description =\"\"\" Web_agent is a capable and autonomous web exploration agent designed to browse, analyze, and extract content from websites. \n",
    "        It can validate links, visit web pages, convert them into clean Markdown, extract hyperlinks for further navigation, and download files if necessary.\n",
    "        Equipped with tools for safe and efficient web scraping, the agent is ideal for tasks like retrieving documents, discovering resources, crawling sites\n",
    "        or building datasets from public data portals. You are WebNavigatorAgent, a specialized web assistant working under the supervision of a manager agent. \n",
    "        Your mission is to search, retrieve, and structure meaningful information related to the Assemblée nationale (French National Assembly).\"\"\"\n",
    "        )\n",
    "\n",
    "#############################################################\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    tools = [],\n",
    "    model = model,\n",
    "    managed_agents = [web_agent, data_agent, rag_agent],\n",
    "    additional_authorized_imports = [\"time\", \"numpy\", \"pandas\"],\n",
    "    planning_interval = 3,\n",
    "    verbosity_level = 2,\n",
    "    #add_base_tools = True\n",
    "    max_steps = 10,\n",
    "    description = \"\"\"You are ManagerAgent, an intelligent assistant responsible for answering complex questions about the French National Assembly (Assemblée nationale). Your mission is to analyze the user's query, determine the type of information needed (legal, institutional, statistical, historical, etc.), and orchestrate the best multi-step strategy to provide accurate, well-sourced, and structured answers.\n",
    "\n",
    " Strategy:\n",
    "1. **Always begin with local analysis.**\n",
    "   - Use the local Retrieval-Augmented Generation (RAG) system to search for relevant documents and datasets already available on disk.\n",
    "   - Tools include:\n",
    "     - `find_relevant_documents(query)` — to retrieve the most relevant documents\n",
    "     - `query_document(path, question)` — to extract an answer from a specific document\n",
    "     - `summarize_document(path)` — to generate a summary\n",
    "     - `get_keyword_context(path, keyword)` — to locate passages around a key term\n",
    "\n",
    "2. **If the local search does not yield enough relevant or up-to-date information**, delegate retrieval tasks to `WebNavigatorAgent`, who can:\n",
    "   - Visit and summarize web pages (`visit_webpage`, `summarize_webpage`)\n",
    "   - Extract and classify all links from a webpage (`extract_and_classify_links`)\n",
    "   - Recursively crawl relevant sections of a site (`follow_links_recursive`)\n",
    "   - Search for downloadable files (`list_files_on_page`, `search_file_links_by_keyword`)\n",
    "   - Extract content around a keyword (`get_keyword_context`)\n",
    "   - Download and return datasets (`download_file`)\n",
    "\n",
    "3. **When using WebNavigatorAgent**, be precise in your instructions. Example queries:\n",
    "   - “Search https://data.assemblee-nationale.fr for datasets on legislative activity”\n",
    "   - “Get the Markdown version of the debate on the pension reform from www.assemblee-nationale.fr”\n",
    "   - “Find and download the list of deputies elected in 2022”\n",
    "\n",
    " Response construction:\n",
    "- Once all relevant data is collected (locally or online), analyze and synthesize it.\n",
    "- Provide a structured response with:\n",
    "  - A clear **summary**\n",
    "  - **Source links**\n",
    "  - Key **excerpts** or statistics\n",
    "  - Optional **suggested follow-ups**\n",
    "- Be transparent about whether information came from local files or web sources.\n",
    "\n",
    "Notes:\n",
    "- If the user asks about something very recent or unindexed, expect to call WebNavigatorAgent.\n",
    "- If the user gives a specific file path, jump directly to `query_document()` or `summarize_document()`.\n",
    "\n",
    "Your job is not just to fetch, but to **curate**, **explain**, and **guide**.\n",
    "\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25908eaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (504797157.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mweb_agent.system_prompt =\u001b[39m\n                             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "web_agent.system_prompt =\n",
    "\"\"\"You are equipped with the following tools:\n",
    "1. `check_url_validity` — Verify if a URL is reachable. Always use this first.\n",
    "2. `visit_webpage` — Visit and convert a webpage to Markdown for readable content.\n",
    "3. `extract_links` — Extract all hyperlinks from a page to explore further.\n",
    "4. `download_file` — Download any available file if relevant. The downloaded file mus be place at '/users/formation/irtn7prtnc/llm_engineering/Cache'\n",
    "\n",
    "Your search priority is as follows:\n",
    "\n",
    "1. Always begin by exploring these official websites:\n",
    "- https://data.assemblee-nationale.fr\n",
    "- https://www.assemblee-nationale.fr\n",
    "\n",
    "Try to locate relevant pages, datasets, documents or structured information directly from these domains.\n",
    "\n",
    "2. If nothing relevant is found, you may expand your search to the broader internet.\n",
    "\n",
    "Use tools one at a time, with precision. Think step-by-step. Only extract or download what is useful for answering the manager agent’s request.\"\"\"\n",
    "            \n",
    "            \n",
    "data_agent.system_prompt =\n",
    "\"\"\"You are DataAgent, an intelligent assistant specialized in analyzing and retrieving insights from local documents.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "1. `find_relevant_documents(query: str)`  \n",
    "   - Use this when the user is searching for specific information or asking a general question.\n",
    "   - It returns a list of local files most relevant to the query using a retrieval-augmented generation system.\n",
    "\n",
    "2. `list_available_documents()`  \n",
    "   - Use this to see which documents are currently indexed or available for analysis.\n",
    "\n",
    "3. `summarize_document(path: str)`  \n",
    "   - Use this when the user wants a high-level overview of a specific document without reading it entirely.\n",
    "\n",
    "4. `query_document(path: str, question: str)`  \n",
    "   - Use this when the user wants an answer derived only from a specific document.\n",
    "\n",
    "5. `get_document_metadata(path: str)`  \n",
    "   - Use this to inspect metadata like file type, size, and modification date.\n",
    "\n",
    "6. `detect_and_parse(path: str)`  \n",
    "   - Automatically detects and parses the file based on extension (PDF, CSV, JSON, XML). Use this when unsure about file format.\n",
    "\n",
    "7. `parse_pdf(path: str)` / `parse_csv(path: str)` / `parse_json(path: str)` / `parse_xml(path: str)`  \n",
    "   - Use these to extract raw content from a specific document type.\n",
    "\n",
    "8. `get_keyword_context(path: str, keyword: str, window: int)`  \n",
    "   - Use this to extract snippets surrounding a keyword inside a document.\n",
    "\n",
    "You should ask clarifying questions if the user provides insufficient detail (e.g., which document to query).  \n",
    "Think step-by-step, choose the correct tool based on the user’s intent, and explain your reasoning clearly.\n",
    "\n",
    "If the user provides a file path, validate and process it using `detect_and_parse`.  \n",
    "If the user asks “what is this file about?”, consider using `summarize_document`.  \n",
    "If they want to search across all files, use `find_relevant_documents`.\n",
    "\n",
    "Be helpful, accurate, and efficient.\"\"\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb271ca",
   "metadata": {},
   "source": [
    "# Utilisation de l'agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f623ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Give me the first and  the last time Jean Lassale was ellected as french depute</span>                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - ollama/qwen2.5-coder:32b ───────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mGive me the first and  the last time Jean Lassale was ellected as french depute\u001b[0m                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - ollama/qwen2.5-coder:32b \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">────────────────────────────────────────────────── <span style=\"font-weight: bold\">Initial plan</span> ───────────────────────────────────────────────────\n",
       "Here is the plan of action that I will follow to solve the task:\n",
       "```\n",
       "1. Request Web_agent to search for reliable sources on the French National Assembly website or other official \n",
       "political archives to find information about Jean Lassale's election history.\n",
       "2. Once Web_agent retrieves the relevant documents, request Data_agent to analyze these documents and extract \n",
       "specific details regarding Jean Lassale's first and last elections as a French député.\n",
       "3. Verify the extracted information by cross-referencing with other sources if necessary, using Web_agent again.\n",
       "4. Ensure all data points are accurate and consistent by double-checking with RAG_Agent to retrieve any previously \n",
       "stored relevant information.\n",
       "5. Compile the final answer from the verified details obtained from Data_agent and RAG_Agent.\n",
       "6. Provide the final answer to the user through the final_answer tool.\n",
       "\n",
       "\n",
       "```\n",
       "</pre>\n"
      ],
      "text/plain": [
       "────────────────────────────────────────────────── \u001b[1mInitial plan\u001b[0m ───────────────────────────────────────────────────\n",
       "Here is the plan of action that I will follow to solve the task:\n",
       "```\n",
       "1. Request Web_agent to search for reliable sources on the French National Assembly website or other official \n",
       "political archives to find information about Jean Lassale's election history.\n",
       "2. Once Web_agent retrieves the relevant documents, request Data_agent to analyze these documents and extract \n",
       "specific details regarding Jean Lassale's first and last elections as a French député.\n",
       "3. Verify the extracted information by cross-referencing with other sources if necessary, using Web_agent again.\n",
       "4. Ensure all data points are accurate and consistent by double-checking with RAG_Agent to retrieve any previously \n",
       "stored relevant information.\n",
       "5. Compile the final answer from the verified details obtained from Data_agent and RAG_Agent.\n",
       "6. Provide the final answer to the user through the final_answer tool.\n",
       "\n",
       "\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Output message of the LLM:</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Thought: I will start by requesting Web_agent to search for reliable sources on Jean Lassale's election history. </span><span style=\"background-color: #0d1117\">  </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">This will include his first and last times he was elected as a French député.</span><span style=\"background-color: #0d1117\">                                      </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Code:</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">```py</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Web_agent(task</span><span style=\"color: #ff7b72; text-decoration-color: #ff7b72; background-color: #0d1117; font-weight: bold\">=</span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">\"Search for reliable sources on the official website of the Assemblée nationale or other official </span><span style=\"background-color: #0d1117\">  </span>\n",
       "<span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">political archives to find information about Jean Lassale's election history.\"</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">)</span><span style=\"background-color: #0d1117\">                                    </span>\n",
       "<span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">```</span><span style=\"background-color: #0d1117\">                                                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3mOutput message of the LLM:\u001b[0m \u001b[38;2;212;183;2m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mThought:\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwill\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mstart\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mby\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mrequesting\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mWeb_agent\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23msearch\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfor\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mreliable\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23msources\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mon\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mJean\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mLassale's\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23melection\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mhistory.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m  \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mThis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwill\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minclude\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mhis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfirst\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlast\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtimes\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mhe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mwas\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23melected\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mas\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23ma\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mFrench\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mdéputé.\u001b[0m\u001b[48;2;13;17;23m                                      \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mCode:\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;165;214;255;48;2;13;17;23m```\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23mpy\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mWeb_agent\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m(\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtask\u001b[0m\u001b[1;38;2;255;123;114;48;2;13;17;23m=\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23mSearch for reliable sources on the official website of the Assemblée nationale or other official \u001b[0m\u001b[48;2;13;17;23m  \u001b[0m\n",
       "\u001b[38;2;165;214;255;48;2;13;17;23mpolitical archives to find information about Jean Lassale\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m'\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23ms election history.\u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m\"\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m)\u001b[0m\u001b[48;2;13;17;23m                                    \u001b[0m\n",
       "\u001b[38;2;165;214;255;48;2;13;17;23m```\u001b[0m\u001b[48;2;13;17;23m                                                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Web_agent(task</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Search for reliable sources on the official website of the Assemblée nationale or other </span><span style=\"background-color: #272822\">       </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">official political archives to find information about Jean Lassale's election history.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                       </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mWeb_agent\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtask\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mSearch for reliable sources on the official website of the Assemblée nationale or other \u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mofficial political archives to find information about Jean Lassale\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms election history.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                       \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run - Web_agent</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ──────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You're a helpful agent named 'Web_agent'.</span>                                                                       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You have been submitted this task by your manager.</span>                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">---</span>                                                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Task:</span>                                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Search for reliable sources on the official website of the Assemblée nationale or other official political </span>     <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">archives to find information about Jean Lassale's election history.</span>                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">---</span>                                                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You're helping your manager solve a wider task: so make sure to not provide a one-line answer, but give as much</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">information as possible to give them a clear understanding of the answer.</span>                                       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Your final_answer WILL HAVE to contain these parts:</span>                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">### 1. Task outcome (short version):</span>                                                                            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">### 2. Task outcome (extremely detailed version):</span>                                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">### 3. Additional context (if relevant):</span>                                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Put all these in your final_answer tool, everything that you do not pass as an argument to final_answer will be</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">lost.</span>                                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">And even if your task resolution is not successful, please return as much context as possible, so that your </span>    <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">manager can act upon this feedback.</span>                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - ollama/qwen2.5-coder:32b ───────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run - Web_agent\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou're a helpful agent named 'Web_agent'.\u001b[0m                                                                       \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou have been submitted this task by your manager.\u001b[0m                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m---\u001b[0m                                                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mTask:\u001b[0m                                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mSearch for reliable sources on the official website of the Assemblée nationale or other official political \u001b[0m     \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1marchives to find information about Jean Lassale's election history.\u001b[0m                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m---\u001b[0m                                                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou're helping your manager solve a wider task: so make sure to not provide a one-line answer, but give as much\u001b[0m \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1minformation as possible to give them a clear understanding of the answer.\u001b[0m                                       \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYour final_answer WILL HAVE to contain these parts:\u001b[0m                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m### 1. Task outcome (short version):\u001b[0m                                                                            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m### 2. Task outcome (extremely detailed version):\u001b[0m                                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m### 3. Additional context (if relevant):\u001b[0m                                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mPut all these in your final_answer tool, everything that you do not pass as an argument to final_answer will be\u001b[0m \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mlost.\u001b[0m                                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mAnd even if your task resolution is not successful, please return as much context as possible, so that your \u001b[0m    \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mmanager can act upon this feedback.\u001b[0m                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - ollama/qwen2.5-coder:32b \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'Jean Lassale election history Assemblée nationale'}       │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'Jean Lassale election history Assemblée nationale'}       │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error whene executing tool web_search with arguments {</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'query'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'Jean Lassale election history Assemblée </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">nationale'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}: DuckDuckGoSearchException: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://html.duckduckgo.com/html</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">202</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Ratelimit</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">You should only use this tool with a correct input.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">As a reminder, this tool's description is the following: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'Performs a duckduckgo web search based on your query </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(think a Google search) then returns the top search results.'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">It takes inputs: {</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'query'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: {</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'type'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'string'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'description'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'The search query to perform.'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}} and returns output </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">type string</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError whene executing tool web_search with arguments \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m'query'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m'Jean Lassale election history Assemblée \u001b[0m\n",
       "\u001b[1;31mnationale'\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m: DuckDuckGoSearchException: \u001b[0m\u001b[1;4;31mhttps://html.duckduckgo.com/html\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m202\u001b[0m\u001b[1;31m Ratelimit\u001b[0m\n",
       "\u001b[1;31mYou should only use this tool with a correct input.\u001b[0m\n",
       "\u001b[1;31mAs a reminder, this tool's description is the following: \u001b[0m\u001b[1;31m'Performs a duckduckgo web search based on your query \u001b[0m\n",
       "\u001b[1;31m(\u001b[0m\u001b[1;31mthink a Google search\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m then returns the top search results.'\u001b[0m\u001b[1;31m.\u001b[0m\n",
       "\u001b[1;31mIt takes inputs: \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m'query'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m'type'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m'string'\u001b[0m\u001b[1;31m, \u001b[0m\u001b[1;31m'description'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m'The search query to perform.'\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m and returns output \u001b[0m\n",
       "\u001b[1;31mtype string\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 8.53 seconds| Input tokens: 2,896 | Output tokens: 31]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 8.53 seconds| Input tokens: 2,896 | Output tokens: 31]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'Jean Lassale election history Assemblée nationale         │\n",
       "│ official site'}                                                                                                 │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'Jean Lassale election history Assemblée nationale         │\n",
       "│ official site'}                                                                                                 │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error whene executing tool web_search with arguments {</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'query'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'Jean Lassale election history Assemblée nationale </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">official site'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}: DuckDuckGoSearchException: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://html.duckduckgo.com/html</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">202</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Ratelimit</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">You should only use this tool with a correct input.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">As a reminder, this tool's description is the following: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'Performs a duckduckgo web search based on your query </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(think a Google search) then returns the top search results.'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">It takes inputs: {</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'query'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: {</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'type'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'string'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'description'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'The search query to perform.'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}} and returns output </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">type string</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError whene executing tool web_search with arguments \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m'query'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m'Jean Lassale election history Assemblée nationale \u001b[0m\n",
       "\u001b[1;31mofficial site'\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m: DuckDuckGoSearchException: \u001b[0m\u001b[1;4;31mhttps://html.duckduckgo.com/html\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m202\u001b[0m\u001b[1;31m Ratelimit\u001b[0m\n",
       "\u001b[1;31mYou should only use this tool with a correct input.\u001b[0m\n",
       "\u001b[1;31mAs a reminder, this tool's description is the following: \u001b[0m\u001b[1;31m'Performs a duckduckgo web search based on your query \u001b[0m\n",
       "\u001b[1;31m(\u001b[0m\u001b[1;31mthink a Google search\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m then returns the top search results.'\u001b[0m\u001b[1;31m.\u001b[0m\n",
       "\u001b[1;31mIt takes inputs: \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m'query'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m'type'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m'string'\u001b[0m\u001b[1;31m, \u001b[0m\u001b[1;31m'description'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m'The search query to perform.'\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m and returns output \u001b[0m\n",
       "\u001b[1;31mtype string\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 4.39 seconds| Input tokens: 6,075 | Output tokens: 60]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 4.39 seconds| Input tokens: 6,075 | Output tokens: 60]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'Jean Lassale Assemblée nationale election history         │\n",
       "│ official archive'}                                                                                              │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'Jean Lassale Assemblée nationale election history         │\n",
       "│ official archive'}                                                                                              │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error whene executing tool web_search with arguments {</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'query'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'Jean Lassale Assemblée nationale election history </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">official archive'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}: DuckDuckGoSearchException: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://html.duckduckgo.com/html</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> RuntimeError: error sending request</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">for url (</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; text-decoration: underline\">https://html.duckduckgo.com/html):</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> client error (SendRequest)</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Caused by:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: client error (SendRequest)</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: connection error</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">    </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: stream closed because of a broken pipe</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">You should only use this tool with a correct input.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">As a reminder, this tool's description is the following: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'Performs a duckduckgo web search based on your query </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(think a Google search) then returns the top search results.'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">It takes inputs: {</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'query'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: {</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'type'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'string'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'description'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'The search query to perform.'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}} and returns output </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">type string</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError whene executing tool web_search with arguments \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m'query'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m'Jean Lassale Assemblée nationale election history \u001b[0m\n",
       "\u001b[1;31mofficial archive'\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m: DuckDuckGoSearchException: \u001b[0m\u001b[1;4;31mhttps://html.duckduckgo.com/html\u001b[0m\u001b[1;31m RuntimeError: error sending request\u001b[0m\n",
       "\u001b[1;31mfor url \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;4;31mhttps://html.duckduckgo.com/html\u001b[0m\u001b[1;4;31m)\u001b[0m\u001b[1;4;31m:\u001b[0m\u001b[1;31m client error \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mSendRequest\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\n",
       "\u001b[1;31mCaused by:\u001b[0m\n",
       "\u001b[1;31m    \u001b[0m\u001b[1;31m0\u001b[0m\u001b[1;31m: client error \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mSendRequest\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\u001b[1;31m    \u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m: connection error\u001b[0m\n",
       "\u001b[1;31m    \u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m: stream closed because of a broken pipe\u001b[0m\n",
       "\u001b[1;31mYou should only use this tool with a correct input.\u001b[0m\n",
       "\u001b[1;31mAs a reminder, this tool's description is the following: \u001b[0m\u001b[1;31m'Performs a duckduckgo web search based on your query \u001b[0m\n",
       "\u001b[1;31m(\u001b[0m\u001b[1;31mthink a Google search\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m then returns the top search results.'\u001b[0m\u001b[1;31m.\u001b[0m\n",
       "\u001b[1;31mIt takes inputs: \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m'query'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m'type'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m'string'\u001b[0m\u001b[1;31m, \u001b[0m\u001b[1;31m'description'\u001b[0m\u001b[1;31m: \u001b[0m\u001b[1;31m'The search query to perform.'\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m and returns output \u001b[0m\n",
       "\u001b[1;31mtype string\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 4.06 seconds| Input tokens: 9,537 | Output tokens: 91]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 4.06 seconds| Input tokens: 9,537 | Output tokens: 91]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m4\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 0.91 seconds| Input tokens: 12,999 | Output tokens: 122]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 0.91 seconds| Input tokens: 12,999 | Output tokens: 122]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 40.23 seconds| Input tokens: 3,462 | Output tokens: 31]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 40.23 seconds| Input tokens: 3,462 | Output tokens: 31]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m agent_output = \u001b[43mmanager_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGive me the first and  the last time Jean Lassale was ellected as french depute\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinal output:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(agent_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/agents.py:376\u001b[39m, in \u001b[36mMultiStepAgent.run\u001b[39m\u001b[34m(self, task, stream, reset, images, additional_args)\u001b[39m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run(task=\u001b[38;5;28mself\u001b[39m.task, images=images)\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# Outputs are returned only at the end as a string. We only look at the last step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/agents.py:405\u001b[39m, in \u001b[36mMultiStepAgent._run\u001b[39m\u001b[34m(self, task, images)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28mself\u001b[39m.logger.log_rule(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.step_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, level=LogLevel.INFO)\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# Run one step!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m final_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m final_answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.final_answer_checks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m check_function \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.final_answer_checks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/agents.py:883\u001b[39m, in \u001b[36mCodeAgent.step\u001b[39m\u001b[34m(self, memory_step)\u001b[39m\n\u001b[32m    881\u001b[39m is_final_answer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m     output, execution_logs, is_final_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpython_executor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    887\u001b[39m     execution_outputs_console = []\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(execution_logs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/local_python_executor.py:1412\u001b[39m, in \u001b[36mLocalPythonInterpreter.__call__\u001b[39m\u001b[34m(self, code_action, additional_variables)\u001b[39m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code_action: \u001b[38;5;28mstr\u001b[39m, additional_variables: Dict) -> Tuple[Any, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m]:\n\u001b[32m   1411\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.update(additional_variables)\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m     output, is_final_answer = \u001b[43mevaluate_python_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatic_tools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatic_tools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_tools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcustom_tools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauthorized_imports\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauthorized_imports\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_print_outputs_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_print_outputs_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1420\u001b[39m     logs = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.state[\u001b[33m\"\u001b[39m\u001b[33m_print_outputs\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output, logs, is_final_answer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/local_python_executor.py:1367\u001b[39m, in \u001b[36mevaluate_python_code\u001b[39m\u001b[34m(code, static_tools, custom_tools, state, authorized_imports, max_print_outputs_length)\u001b[39m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m expression.body:\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m         result = \u001b[43mevaluate_ast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_tools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_tools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthorized_imports\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1368\u001b[39m     state[\u001b[33m\"\u001b[39m\u001b[33m_print_outputs\u001b[39m\u001b[33m\"\u001b[39m].value = truncate_content(\n\u001b[32m   1369\u001b[39m         \u001b[38;5;28mstr\u001b[39m(state[\u001b[33m\"\u001b[39m\u001b[33m_print_outputs\u001b[39m\u001b[33m\"\u001b[39m]), max_length=max_print_outputs_length\n\u001b[32m   1370\u001b[39m     )\n\u001b[32m   1371\u001b[39m     is_final_answer = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/local_python_executor.py:1230\u001b[39m, in \u001b[36mevaluate_ast\u001b[39m\u001b[34m(expression, state, static_tools, custom_tools, authorized_imports)\u001b[39m\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, values))\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(expression, ast.Expr):\n\u001b[32m   1229\u001b[39m     \u001b[38;5;66;03m# Expression -> evaluate the content\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate_ast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpression\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_tools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_tools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthorized_imports\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(expression, ast.For):\n\u001b[32m   1232\u001b[39m     \u001b[38;5;66;03m# For loop -> execute the loop\u001b[39;00m\n\u001b[32m   1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluate_for(expression, state, static_tools, custom_tools, authorized_imports)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/local_python_executor.py:1192\u001b[39m, in \u001b[36mevaluate_ast\u001b[39m\u001b[34m(expression, state, static_tools, custom_tools, authorized_imports)\u001b[39m\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluate_augassign(expression, state, static_tools, custom_tools, authorized_imports)\n\u001b[32m   1190\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(expression, ast.Call):\n\u001b[32m   1191\u001b[39m     \u001b[38;5;66;03m# Function call -> we return the value of the function call\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_tools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_tools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthorized_imports\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(expression, ast.Constant):\n\u001b[32m   1194\u001b[39m     \u001b[38;5;66;03m# Constant -> just return the value\u001b[39;00m\n\u001b[32m   1195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m expression.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/local_python_executor.py:643\u001b[39m, in \u001b[36mevaluate_call\u001b[39m\u001b[34m(call, state, static_tools, custom_tools, authorized_imports)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    636\u001b[39m     (inspect.getmodule(func) == builtins)\n\u001b[32m    637\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m inspect.isbuiltin(func)\n\u001b[32m    638\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (func \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m static_tools.values())\n\u001b[32m    639\u001b[39m ):\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InterpreterError(\n\u001b[32m    641\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvoking a builtin function that has not been explicitly added as a tool is not allowed (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    642\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/agents.py:617\u001b[39m, in \u001b[36mMultiStepAgent.__call__\u001b[39m\u001b[34m(self, task, **kwargs)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    610\u001b[39m \u001b[33;03mThis methd is called only by a manager agent.\u001b[39;00m\n\u001b[32m    611\u001b[39m \u001b[33;03mAdds additional prompting for the managed agent, runs it, and wraps the output.\u001b[39;00m\n\u001b[32m    612\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    613\u001b[39m full_task = populate_template(\n\u001b[32m    614\u001b[39m     \u001b[38;5;28mself\u001b[39m.prompt_templates[\u001b[33m\"\u001b[39m\u001b[33mmanaged_agent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    615\u001b[39m     variables=\u001b[38;5;28mdict\u001b[39m(name=\u001b[38;5;28mself\u001b[39m.name, task=task),\n\u001b[32m    616\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m report = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    618\u001b[39m answer = populate_template(\n\u001b[32m    619\u001b[39m     \u001b[38;5;28mself\u001b[39m.prompt_templates[\u001b[33m\"\u001b[39m\u001b[33mmanaged_agent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mreport\u001b[39m\u001b[33m\"\u001b[39m], variables=\u001b[38;5;28mdict\u001b[39m(name=\u001b[38;5;28mself\u001b[39m.name, final_answer=report)\n\u001b[32m    620\u001b[39m )\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.provide_run_summary:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/agents.py:376\u001b[39m, in \u001b[36mMultiStepAgent.run\u001b[39m\u001b[34m(self, task, stream, reset, images, additional_args)\u001b[39m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run(task=\u001b[38;5;28mself\u001b[39m.task, images=images)\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# Outputs are returned only at the end as a string. We only look at the last step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/agents.py:405\u001b[39m, in \u001b[36mMultiStepAgent._run\u001b[39m\u001b[34m(self, task, images)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28mself\u001b[39m.logger.log_rule(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.step_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, level=LogLevel.INFO)\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# Run one step!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m final_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m final_answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.final_answer_checks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m check_function \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.final_answer_checks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/agents.py:681\u001b[39m, in \u001b[36mToolCallingAgent.step\u001b[39m\u001b[34m(self, memory_step)\u001b[39m\n\u001b[32m    678\u001b[39m memory_step.model_input_messages = memory_messages.copy()\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     model_message: ChatMessage = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools_to_call_from\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mObservation:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m     memory_step.model_output_message = model_message\n\u001b[32m    687\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_message.tool_calls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_message.tool_calls) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/smolagents/models.py:703\u001b[39m, in \u001b[36mLiteLLMModel.__call__\u001b[39m\u001b[34m(self, messages, stop_sequences, grammar, tools_to_call_from, **kwargs)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\n\u001b[32m    689\u001b[39m completion_kwargs = \u001b[38;5;28mself\u001b[39m._prepare_completion_kwargs(\n\u001b[32m    690\u001b[39m     messages=messages,\n\u001b[32m    691\u001b[39m     stop_sequences=stop_sequences,\n\u001b[32m   (...)\u001b[39m\u001b[32m    700\u001b[39m     **kwargs,\n\u001b[32m    701\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m response = \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;28mself\u001b[39m.last_input_token_count = response.usage.prompt_tokens\n\u001b[32m    706\u001b[39m \u001b[38;5;28mself\u001b[39m.last_output_token_count = response.usage.completion_tokens\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/litellm/utils.py:900\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    898\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    899\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    901\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/litellm/main.py:2678\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[39m\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mollama\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2672\u001b[39m     api_base = (\n\u001b[32m   2673\u001b[39m         litellm.api_base\n\u001b[32m   2674\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m api_base\n\u001b[32m   2675\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m get_secret(\u001b[33m\"\u001b[39m\u001b[33mOLLAMA_API_BASE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2676\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:11434\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2677\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2678\u001b[39m     response = \u001b[43mbase_llm_http_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2679\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2686\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mollama\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# model call logging done inside the class as we make need to modify I/O to fit aleph alpha's requirements\u001b[39;49;00m\n\u001b[32m   2693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2694\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2696\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mollama_chat\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2697\u001b[39m     api_base = (\n\u001b[32m   2698\u001b[39m         litellm.api_base\n\u001b[32m   2699\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m api_base\n\u001b[32m   2700\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m get_secret(\u001b[33m\"\u001b[39m\u001b[33mOLLAMA_API_BASE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2701\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:11434\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2702\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:325\u001b[39m, in \u001b[36mBaseLLMHTTPHandler.completion\u001b[39m\u001b[34m(self, model, messages, api_base, custom_llm_provider, model_response, encoding, logging_obj, optional_params, timeout, litellm_params, acompletion, stream, fake_stream, api_key, headers, client)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    323\u001b[39m     sync_httpx_client = client\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_common_sync_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43msync_httpx_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43msync_httpx_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m provider_config.transform_response(\n\u001b[32m    335\u001b[39m     model=model,\n\u001b[32m    336\u001b[39m     raw_response=response,\n\u001b[32m   (...)\u001b[39m\u001b[32m    344\u001b[39m     encoding=encoding,\n\u001b[32m    345\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:107\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._make_common_sync_call\u001b[39m\u001b[34m(self, sync_httpx_client, provider_config, api_base, headers, data, timeout, litellm_params, stream)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmax\u001b[39m(max_retry_on_unprocessable_entity_error, \u001b[32m1\u001b[39m)):\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m         response = \u001b[43msync_httpx_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    115\u001b[39m         hit_max_retry = i + \u001b[32m1\u001b[39m == max_retry_on_unprocessable_entity_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py:508\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    505\u001b[39m     req = \u001b[38;5;28mself\u001b[39m.client.build_request(\n\u001b[32m    506\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m, url, data=data, json=json, params=params, headers=headers, files=files, content=content  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    507\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    509\u001b[39m response.raise_for_status()\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpx/_client.py:926\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    924\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpx/_client.py:954\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    951\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    960\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpx/_client.py:991\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    989\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    993\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpx/_client.py:1027\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m     )\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1031\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    223\u001b[39m req = httpcore.Request(\n\u001b[32m    224\u001b[39m     method=request.method,\n\u001b[32m    225\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     extensions=request.extensions,\n\u001b[32m    234\u001b[39m )\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    241\u001b[39m     status_code=resp.status,\n\u001b[32m    242\u001b[39m     headers=resp.headers,\n\u001b[32m    243\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    244\u001b[39m     extensions=resp.extensions,\n\u001b[32m    245\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/valdom_env/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "agent_output = manager_agent.run('Give me the first and  the last time Jean Lassale was ellected as french depute')\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120283ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valdom_env",
   "language": "python",
   "name": "valdom_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
